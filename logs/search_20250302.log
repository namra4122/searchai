2025-03-02 19:12:33,008 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:12:33,009 - searchai.cli.interface - INFO - interface.py:<module>:39 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:12:33,009 - searchai.cli.interface - INFO - interface.py:search:120 - Search request - Query: What is AI?, Format: markdown
2025-03-02 19:12:33,009 - searchai.cli.interface - DEBUG - interface.py:search:131 - ---------- searchai/cli/interface.py - search() - start ----------
2025-03-02 19:12:33,009 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:12:33,010 - searchai.cli.interface - DEBUG - interface.py:search:141 - ---------- searchai/cli/interface.py - new_event_loop() - start ----------
2025-03-02 19:12:33,010 - searchai.cli.interface - DEBUG - interface.py:process_search:51 - ---------- searchai/cli/interface.py - process_search() - start ----------
2025-03-02 19:12:33,010 - searchai.cli.interface - DEBUG - interface.py:process_search:60 - ---------- searchai/cli/interface.py - process_search() - progress.add_task(searching web) ----------
2025-03-02 19:12:33,011 - searchai.search.crew_search - INFO - crew_search.py:perform_web_search:215 - Performing web search for: What is AI?
2025-03-02 19:12:33,011 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:12:33,011 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:12:33,023 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:12:34,298 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select pg_catalog.version()
2025-03-02 19:12:34,301 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:12:34,492 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select current_schema()
2025-03-02 19:12:34,494 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:12:34,694 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - show standard_conforming_strings
2025-03-02 19:12:34,696 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:12:34,833 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:12:34,841 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:12:34,843 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00201s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:12:35,007 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:12:35,009 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.1687s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:12:35,054 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:12:35,057 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.2162s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:12:35,124 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 19:12:35,126 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00225s] ('outputformat', 'pg_catalog')
2025-03-02 19:12:35,217 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:12:35,263 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:70 - Verifying database tables...
2025-03-02 19:12:35,263 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:12:35,264 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:12:35,266 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 19:12:35,267 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00105s] ()
2025-03-02 19:12:35,426 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:81 - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:12:35,427 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:12:35,470 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:12:35,471 - searchai.db.db_handler - INFO - db_handler.py:init_db:105 - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:12:35,471 - searchai.db.db_handler - INFO - db_handler.py:init_db:111 - Database initialized
2025-03-02 19:12:35,471 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:113 - ---------- searchai/db/db_handler.py - init_db() - end ----------
2025-03-02 19:12:35,471 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:127 - ---------- searchai/db/db_handler.py - log_user_query() - start ----------
2025-03-02 19:12:35,471 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:12:35,474 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:12:35,477 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 19:12:35,478 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00136s] ('315705ab-ffb1-481e-ba86-ba4e9db5080e', 'What is AI?', 'MARKDOWN', 'pending')
2025-03-02 19:12:35,927 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:12:35,976 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:12:35,981 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 19:12:35,984 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00326s] ('315705ab-ffb1-481e-ba86-ba4e9db5080e',)
2025-03-02 19:12:36,118 - searchai.db.db_handler - INFO - db_handler.py:log_user_query:146 - Logged user query: 315705ab-ffb1-481e-ba86-ba4e9db5080e
2025-03-02 19:12:36,119 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:12:36,167 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:12:36,168 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:154 - ---------- searchai/db/db_handler.py - log_user_query() - end ----------
2025-03-02 19:12:36,168 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:165 - ---------- searchai/db/db_handler.py - update_query_status() - start ----------
2025-03-02 19:12:36,168 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:12:36,170 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:12:36,174 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 19:12:36,176 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00168s] ('processing', '315705ab-ffb1-481e-ba86-ba4e9db5080e')
2025-03-02 19:12:36,316 - searchai.db.db_handler - INFO - db_handler.py:update_query_status:169 - Updated query 315705ab-ffb1-481e-ba86-ba4e9db5080e status to processing
2025-03-02 19:12:36,316 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:12:36,360 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:12:36,361 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:171 - ---------- searchai/db/db_handler.py - update_query_status() - end ----------
2025-03-02 19:12:36,361 - searchai.search.crew_search - INFO - crew_search.py:search:114 - Starting web search for query: What is AI?
2025-03-02 19:12:36,362 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:56 - ---------- searchai/search/crew_search.py - _run_crew() - start ----------
2025-03-02 19:12:36,362 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:59 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:12:36,366 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:70 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:12:36,366 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:74 - ---------- searchai/search/crew_search.py - search task - start----------
2025-03-02 19:12:36,368 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:92 - ---------- searchai/search/crew_search.py - search task - end ----------
2025-03-02 19:12:36,386 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:12:36,386 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mRequest to litellm:[0m
2025-03-02 19:12:36,386 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mlitellm.completion(model='gemini/gemini-1.5-pro-latest', messages=[{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], stop=['\nObservation:'], stream=False)[0m
2025-03-02 19:12:36,387 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:12:36,387 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x3020e4610>]
2025-03-02 19:12:36,387 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {}
2025-03-02 19:12:36,387 - LiteLLM - DEBUG - utils.py:print_verbose:298 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-03-02 19:12:36,396 - LiteLLM - DEBUG - transformation.py:translate_developer_role_to_system_role:115 - Translating developer role to system role for non-OpenAI providers.
2025-03-02 19:12:36,396 - LiteLLM - INFO - utils.py:_check_valid_arg:2896 - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 19:12:36,396 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2899 - 
LiteLLM: Params passed to completion() {'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'reasoning_effort': None, 'messages': [{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], 'additional_drop_params': None, 'custom_llm_provider': 'gemini', 'drop_params': None, 'model': 'gemini-1.5-pro-latest', 'n': None}
2025-03-02 19:12:36,396 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2902 - 
LiteLLM: Non-Default params passed to completion() {'stream': False, 'stop': ['\nObservation:']}
2025-03-02 19:12:36,396 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Final returned optional params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:12:36,396 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:12:36,398 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:12:36,399 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:12:36,405 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:12:36,405 - LiteLLM - DEBUG - litellm_logging.py:_print_llm_call_debugging_log:634 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU \
-H 'Content-Type: *****' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}]}, 'generationConfig': {'stop_sequences': ['\nObservation:']}}'
[0m

2025-03-02 19:12:36,406 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:12:36,406 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:12:36,411 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-03-02 19:12:36,434 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3020e6080>
2025-03-02 19:12:36,434 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x30205ad40> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-03-02 19:12:36,518 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e2031f0>
2025-03-02 19:12:36,518 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.started request=<Request [b'POST']>
2025-03-02 19:12:36,518 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.complete
2025-03-02 19:12:36,518 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.started request=<Request [b'POST']>
2025-03-02 19:12:36,519 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.complete
2025-03-02 19:12:36,519 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.started request=<Request [b'POST']>
2025-03-02 19:13:00,008 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 02 Mar 2025 13:42:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=23479'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-03-02 19:13:00,010 - httpx - INFO - _client.py:_send_single_request:1038 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 200 OK"
2025-03-02 19:13:00,010 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.started request=<Request [b'POST']>
2025-03-02 19:13:00,017 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.complete
2025-03-02 19:13:00,017 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.started
2025-03-02 19:13:00,017 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.complete
2025-03-02 19:13:00,018 - LiteLLM - DEBUG - utils.py:print_verbose:298 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Thought: I need to search the internet for \"What is AI?\" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {\"search_query\": \"What is AI?\"}\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "citationMetadata": {
        "citationSources": [
          {
            "startIndex": 353,
            "endIndex": 484,
            "uri": "https://online.okcu.edu/nursing/blog/the-latest-on-artificial-intelligence-in-nursing"
          },
          {
            "startIndex": 654,
            "endIndex": 803,
            "uri": "https://www.zenarate.com/blog/large-language-models-analysis/"
          },
          {
            "startIndex": 817,
            "endIndex": 959,
            "uri": "https://inclusivepracticessite.blog/2023/04/"
          },
          {
            "startIndex": 843,
            "endIndex": 999,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 1200,
            "endIndex": 1348,
            "uri": "https://justagriculture.in/blog/artificial-intelligence-for-sustainable-poultry-farming/"
          },
          {
            "startIndex": 1229,
            "endIndex": 1435,
            "uri": "https://kmbs.konicaminolta.us/blog/chatgpt-shines-light-on-the-need-for-scanning-services-and-ocr-capabilities-to-power-automation/"
          },
          {
            "startIndex": 1409,
            "endIndex": 1556,
            "uri": "http://www.dbenjaminlegal.com/voter-vll/4a0708-task-automation-definition"
          },
          {
            "startIndex": 1705,
            "endIndex": 1889,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 2098,
            "endIndex": 2248,
            "uri": "https://dokumen.tips/documents/boost-your-aiqioeaccenture-boost-your-aiq-transforming-into-an-ai-business-2-as.html"
          },
          {
            "startIndex": 2130,
            "endIndex": 2273,
            "uri": "https://thetranslationgate.com/2020/01/04/british-designer-create-arras-3/"
          },
          {
            "startIndex": 2856,
            "endIndex": 3037,
            "uri": "https://www.square2marketing.com/blog/the-robots-are-coming-and-theyre-coming-to-help-you-drive-leads-and-close-more-new-customers"
          },
          {
            "startIndex": 3222,
            "endIndex": 3382,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 3563,
            "endIndex": 3708,
            "uri": "https://slickplan.com/blog/information-architecture-trends"
          },
          {
            "startIndex": 3989,
            "endIndex": 4146,
            "uri": "https://github.com/sirikumari/CodeAlpha_Integrating_Captcha"
          },
          {
            "startIndex": 4226,
            "endIndex": 4363,
            "uri": "https://beta.cragarwheel.com/filedownload?article=20672&FileName=Animal%20Machines.pdf"
          },
          {
            "startIndex": 4291,
            "endIndex": 4417,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 4425,
            "endIndex": 4567,
            "uri": "https://inclusivepracticessite.blog/2023/04/"
          },
          {
            "startIndex": 4451,
            "endIndex": 4607,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 4736,
            "endIndex": 4884,
            "uri": "https://justagriculture.in/blog/artificial-intelligence-for-sustainable-poultry-farming/"
          },
          {
            "startIndex": 4866,
            "endIndex": 5061,
            "uri": "https://www.insightsonindia.com/2022/08/16/day-37-synopsis-75-days-mains-revision-plan-2022-science-technology-ethics/"
          },
          {
            "startIndex": 5169,
            "endIndex": 5353,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 5490,
            "endIndex": 5640,
            "uri": "https://dokumen.tips/documents/boost-your-aiqioeaccenture-boost-your-aiq-transforming-into-an-ai-business-2-as.html"
          },
          {
            "startIndex": 5522,
            "endIndex": 5665,
            "uri": "https://thetranslationgate.com/2020/01/04/british-designer-create-arras-3/"
          },
          {
            "startIndex": 6104,
            "endIndex": 6285,
            "uri": "https://www.square2marketing.com/blog/the-robots-are-coming-and-theyre-coming-to-help-you-drive-leads-and-close-more-new-customers"
          },
          {
            "startIndex": 6398,
            "endIndex": 6558,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 6667,
            "endIndex": 6812,
            "uri": "https://slickplan.com/blog/information-architecture-trends"
          }
        ]
      },
      "avgLogprobs": -1.7921587073284646
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 435,
    "candidatesTokenCount": 46,
    "totalTokenCount": 481,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 435
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 46
      }
    ]
  },
  "modelVersion": "gemini-1.5-pro-002"
}



2025-03-02 19:13:00,019 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.started
2025-03-02 19:13:00,019 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.complete
2025-03-02 19:13:00,020 - LiteLLM - INFO - utils.py:wrapper:1084 - Wrapper: Completed Call, calling success_handler
2025-03-02 19:13:00,020 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1014 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-03-02 19:13:00,021 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:00,021 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:13:00,022 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:13:00,026 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:00,026 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:00,027 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1040 - Logging Details LiteLLM-Success Call streaming complete
2025-03-02 19:13:00,029 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:00,029 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:00,029 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:00,029 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:13:00,030 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:00,030 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:01,035 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:13:01,035 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mRequest to litellm:[0m
2025-03-02 19:13:01,036 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mlitellm.completion(model='gemini/gemini-1.5-pro-latest', messages=[{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 1}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 2}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 3}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 4}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 5}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 6}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 7, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 8, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 9, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is AI in computer\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}], stop=['\nObservation:'], stream=False)[0m
2025-03-02 19:13:01,036 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:13:01,036 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Initialized litellm callbacks, Async Success Callbacks: ['cache', <crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x3020e4610>]
2025-03-02 19:13:01,037 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {}
2025-03-02 19:13:01,037 - LiteLLM - DEBUG - utils.py:print_verbose:298 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-03-02 19:13:01,037 - LiteLLM - DEBUG - transformation.py:translate_developer_role_to_system_role:115 - Translating developer role to system role for non-OpenAI providers.
2025-03-02 19:13:01,037 - LiteLLM - INFO - utils.py:_check_valid_arg:2896 - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 19:13:01,038 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2899 - 
LiteLLM: Params passed to completion() {'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'reasoning_effort': None, 'messages': [{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 1}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 2}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 3}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 4}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 5}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 6}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 7, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 8, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 9, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is AI in computer\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}], 'additional_drop_params': None, 'custom_llm_provider': 'gemini', 'drop_params': None, 'model': 'gemini-1.5-pro-latest', 'n': None}
2025-03-02 19:13:01,038 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2902 - 
LiteLLM: Non-Default params passed to completion() {'stream': False, 'stop': ['\nObservation:']}
2025-03-02 19:13:01,038 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Final returned optional params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:13:01,038 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:13:01,039 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:13:01,039 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:13:01,048 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:01,048 - LiteLLM - DEBUG - litellm_logging.py:_print_llm_call_debugging_log:634 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU \
-H 'Content-Type: *****' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}, {'role': 'model', 'parts': [{'text': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 1}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 2}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 3}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 4}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 5}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 6}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 7, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 8, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 9, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is AI in computer\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}]}], 'system_instruction': {'parts': [{'text': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}]}, 'generationConfig': {'stop_sequences': ['\nObservation:']}}'
[0m

2025-03-02 19:13:01,049 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:13:01,049 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:13:01,056 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-03-02 19:13:01,066 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15769c130>
2025-03-02 19:13:01,066 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x30205b9c0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-03-02 19:13:01,114 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15755ffa0>
2025-03-02 19:13:01,114 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.started request=<Request [b'POST']>
2025-03-02 19:13:01,114 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.complete
2025-03-02 19:13:01,114 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.started request=<Request [b'POST']>
2025-03-02 19:13:01,114 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.complete
2025-03-02 19:13:01,114 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.started request=<Request [b'POST']>
2025-03-02 19:13:09,620 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 02 Mar 2025 13:43:09 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=8495'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-03-02 19:13:09,622 - httpx - INFO - _client.py:_send_single_request:1038 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 200 OK"
2025-03-02 19:13:09,623 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.started request=<Request [b'POST']>
2025-03-02 19:13:09,625 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.complete
2025-03-02 19:13:09,625 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.started
2025-03-02 19:13:09,625 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.complete
2025-03-02 19:13:09,626 - LiteLLM - DEBUG - utils.py:print_verbose:298 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Thought: I now have the search results. I will format them as requested.\n\nFinal Answer:\nhttps://www.ibm.com/think/topics/artificial-intelligence\nWhat Is Artificial Intelligence (AI)? | IBM\nAI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\n\nhttps://en.wikipedia.org/wiki/Artificial_intelligence\nArtificial intelligence - Wikipedia\nArtificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\n\nhttps://www.nasa.gov/what-is-artificial-intelligence/\nWhat is Artificial Intelligence? - NASA\nArtificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\n\nhttps://aws.amazon.com/what-is/artificial-intelligence/\nWhat is AI? - Artificial Intelligence Explained - AWS\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\n\nhttp://jmc.stanford.edu/artificial-intelligence/what-is-ai/\nWhat is AI? / Basic Questions - John McCarthy\nQ. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\n\nhttps://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\nWhat is (AI) Artificial Intelligence? | Online Master of Engineering\nArtificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\n\nhttps://www.mtu.edu/computing/ai/\nWhat is AI? | College of Computing | Michigan Tech\nArtificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\n\nhttps://www.coursera.org/articles/what-is-artificial-intelligence\nWhat Is Artificial Intelligence? Definition, Uses, and Types - Coursera\nArtificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\n\nhttps://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\nWhat is AI (artificial intelligence)? - McKinsey & Company\nAI is a machine's ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "citationMetadata": {
        "citationSources": [
          {
            "startIndex": 953,
            "endIndex": 1087,
            "uri": "https://www.analyticsvidhya.com/blog/2023/07/ai-interview-questions/"
          },
          {
            "startIndex": 1223,
            "endIndex": 1368,
            "uri": "http://www.fredbf.com/disciplinas/unibratec/dsi/whatisAI.doc"
          },
          {
            "startIndex": 2086,
            "endIndex": 2208,
            "uri": "https://www.coursera.org/articles/what-is-artificial-intelligence"
          },
          {
            "startIndex": 2359,
            "endIndex": 2495,
            "uri": "https://www.jllt.com/blog/the-impact-of-ai-on-cre/"
          }
        ]
      },
      "avgLogprobs": -0.00029167486268951527
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 2002,
    "candidatesTokenCount": 543,
    "totalTokenCount": 2545,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 2002
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 543
      }
    ]
  },
  "modelVersion": "gemini-1.5-pro-002"
}



2025-03-02 19:13:09,628 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.started
2025-03-02 19:13:09,628 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.complete
2025-03-02 19:13:09,629 - LiteLLM - INFO - utils.py:wrapper:1084 - Wrapper: Completed Call, calling success_handler
2025-03-02 19:13:09,630 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:09,630 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1014 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-03-02 19:13:09,631 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:09,631 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:09,631 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:09,632 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:09,632 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.00757715
2025-03-02 19:13:09,633 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:09,643 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.00757715
2025-03-02 19:13:09,644 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:09,644 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:09,644 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1040 - Logging Details LiteLLM-Success Call streaming complete
2025-03-02 19:13:09,645 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:13:09,645 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:09,645 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:09,645 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.00757715
2025-03-02 19:13:09,646 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:13:09,646 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:13:09,648 - searchai.search.crew_search - DEBUG - crew_search.py:_parse_results:151 - Raw results: https://www.ibm.com/think/topics/artificial-intelligence
What Is Artificial Intelligence (AI)? | IBM
AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.

https://en.wikipedia.org/wiki/Artificial_intelligence
Artificial intelligence - Wikipedia
Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...

https://www.nasa.gov/what-is-artificial-intelligence/
What is Artificial Intelligence? - NASA
Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.

https://aws.amazon.com/what-is/artificial-intelligence/
What is AI? - Artificial Intelligence Explained - AWS
Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...

http://jmc.stanford.edu/artificial-intelligence/what-is-ai/
What is AI? / Basic Questions - John McCarthy
Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.

https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/
What is (AI) Artificial Intelligence? | Online Master of Engineering
Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...

https://www.mtu.edu/computing/ai/
What is AI? | College of Computing | Michigan Tech
Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...

https://www.coursera.org/articles/what-is-artificial-intelligence
What Is Artificial Intelligence? Definition, Uses, and Types - Coursera
Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.

https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai
What is AI (artificial intelligence)? - McKinsey & Company
AI is a machine's ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...
2025-03-02 19:13:09,649 - searchai.search.crew_search - INFO - crew_search.py:search:131 - Search completed in 33.29 seconds. Found 9 results.
2025-03-02 19:13:09,649 - searchai.db.db_handler - DEBUG - db_handler.py:store_search_results:182 - ---------- searchai/db/db_handler.py - store_search_results() - start ----------
2025-03-02 19:13:09,649 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:13:09,650 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:13:09,653 - sqlalchemy.engine.Engine - INFO - base.py:_exec_insertmany_context:2070 - INSERT INTO search_results (id, query_id, source_url, title, snippet) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR), ($6::VARCHAR, $7::VARCHAR, $8::VARCHAR, $9::VARCHAR, $10::VARCHAR), ($11::VARCHAR, $12::VARCHAR, $13::VARC ... 419 characters truncated ... AR, $43::VARCHAR, $44::VARCHAR, $45::VARCHAR) RETURNING search_results.created_at, search_results.id
2025-03-02 19:13:09,655 - sqlalchemy.engine.Engine - INFO - base.py:_exec_insertmany_context:2089 - [generated in 0.00028s (insertmanyvalues) 1/1 (ordered)] ('ace5d546-6cc6-4b2d-8106-64b9d0ee609f', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://www.ibm.com/think/topics/artificial-intelligence', 'What Is Artificial Intelligence (AI)? | IBM', None, '47eae811-01b2-4362-8418-8d8ed33c674b', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://en.wikipedia.org/wiki/Artificial_intelligence', 'Artificial intelligence - Wikipedia', None, '37ecadc4-c2ba-4c46-a7e9-00e1db7c47b5', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://www.nasa.gov/what-is-artificial-intelligence/', 'What is Artificial Intelligence? - NASA', None, '5102d741-d74f-40e9-a881-c2c47fafd166', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://aws.amazon.com/what-is/artificial-intelligence/', 'What is AI? - Artificial Intelligence Explained - AWS', None, '0c0f6705-963a-4f79-be1c-ea21d6b36353', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/', 'What is AI? / Basic Questions - John McCarthy', None, 'a6417ae2-608e-4f04-bcd8-5f67877b25d3', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/', 'What is (AI) Artificial Intelligence? | Online Master of Engineering', None, '41050987-79b0-41d6-84be-5adf6fdb3633', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://www.mtu.edu/computing/ai/', 'What is AI? | College of Computing | Michigan Tech', None, '0675f238-ff2d-4c57-b056-d90ea07edd4e', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://www.coursera.org/articles/what-is-artificial-intelligence', 'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera', None, '34b75ca4-d295-434f-9137-590cf4285322', '315705ab-ffb1-481e-ba86-ba4e9db5080e', 'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai', 'What is AI (artificial intelligence)? - McKinsey & Company', None)
2025-03-02 19:13:09,795 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:13:09,842 - searchai.db.db_handler - INFO - db_handler.py:store_search_results:193 - Stored 9 search results for query 315705ab-ffb1-481e-ba86-ba4e9db5080e
2025-03-02 19:13:09,843 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:13:09,843 - searchai.db.db_handler - DEBUG - db_handler.py:store_search_results:195 - ---------- searchai/db/db_handler.py - store_search_results() - end ----------
2025-03-02 19:13:09,843 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:165 - ---------- searchai/db/db_handler.py - update_query_status() - start ----------
2025-03-02 19:13:09,843 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:13:09,845 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:13:09,848 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 19:13:09,850 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 33.68s ago] ('completed', '315705ab-ffb1-481e-ba86-ba4e9db5080e')
2025-03-02 19:13:09,935 - searchai.db.db_handler - INFO - db_handler.py:update_query_status:169 - Updated query 315705ab-ffb1-481e-ba86-ba4e9db5080e status to completed
2025-03-02 19:13:09,936 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:13:09,986 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:13:09,987 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:171 - ---------- searchai/db/db_handler.py - update_query_status() - end ----------
2025-03-02 19:13:09,987 - searchai.cli.interface - DEBUG - interface.py:process_search:63 - ---------- searchai/cli/interface.py - process_search() - progress.task(searching web) - completed ----------
2025-03-02 19:13:09,991 - searchai.cli.interface - DEBUG - interface.py:process_search:68 - ---------- searchai/cli/interface.py - process_search() - progress.add_task(process results) ----------
2025-03-02 19:13:09,991 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:287 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - start ----------
2025-03-02 19:13:09,992 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:295 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - reasoner start ----------
2025-03-02 19:13:09,992 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:298 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - reasoner end ----------
2025-03-02 19:13:09,992 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:303 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - try - start ----------
2025-03-02 19:13:09,993 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:47 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - start ----------
2025-03-02 19:13:09,993 - searchai.reasoning.gemini_llm - INFO - gemini_llm.py:generate_content:48 - Generating content for query: What is AI?
2025-03-02 19:13:09,993 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:_create_prompt:98 - ---------- searchai/reasoning/gemini_llm.py - _create_prompt() - start ----------
2025-03-02 19:13:09,994 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:_create_prompt:127 - ---------- searchai/reasoning/gemini_llm.py - _create_prompt() - end ----------
2025-03-02 19:13:09,994 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:55 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - prompt: 
        You are an expert researcher and writer. Your task is to create a comprehensive and well-structured document
        based on the following search results. The document should address this query: "What is AI?"
        
        Here are the search results to use as your source material:
        
        Source 1:
Title: What Is Artificial Intelligence (AI)? | IBM
URL: https://www.ibm.com/think/topics/artificial-intelligence
Summary: No description

Source 2:
Title: Artificial intelligence - Wikipedia
URL: https://en.wikipedia.org/wiki/Artificial_intelligence
Summary: No description

Source 3:
Title: What is Artificial Intelligence? - NASA
URL: https://www.nasa.gov/what-is-artificial-intelligence/
Summary: No description

Source 4:
Title: What is AI? - Artificial Intelligence Explained - AWS
URL: https://aws.amazon.com/what-is/artificial-intelligence/
Summary: No description

Source 5:
Title: What is AI? / Basic Questions - John McCarthy
URL: http://jmc.stanford.edu/artificial-intelligence/what-is-ai/
Summary: No description

Source 6:
Title: What is (AI) Artificial Intelligence? | Online Master of Engineering
URL: https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/
Summary: No description

Source 7:
Title: What is AI? | College of Computing | Michigan Tech
URL: https://www.mtu.edu/computing/ai/
Summary: No description

Source 8:
Title: What Is Artificial Intelligence? Definition, Uses, and Types - Coursera
URL: https://www.coursera.org/articles/what-is-artificial-intelligence
Summary: No description

Source 9:
Title: What is AI (artificial intelligence)? - McKinsey & Company
URL: https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai
Summary: No description


        
        
            Format your response as a Markdown document with:
            1. A clear title (use # for the main title)
            2. Section headers (use ## for major sections and ### for subsections)
            3. Bullet points or numbered lists where appropriate
            4. Bold or italics for emphasis
            5. Code blocks if needed
            6. Citations to the source material
            
            IMPORTANT: Do NOT wrap the entire response in markdown code blocks (```).
            Write the content directly in markdown format.
            
        
        Make sure your response is informative, accurate, and directly answers the query. Use the provided search results
        as your primary source of information. If you need to make educated guesses or inferences, clearly indicate them.
        
        Write the document now.
         ----------
2025-03-02 19:13:09,994 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:59 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - _get_generation_config - start ----------
2025-03-02 19:13:09,994 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:62 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - _get_generation_config - end ----------
2025-03-02 19:13:21,189 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:76 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - end ----------
2025-03-02 19:13:21,190 - searchai.reasoning.gemini_llm - INFO - gemini_llm.py:generate_content:77 - Content generation completed in 11.20 seconds
2025-03-02 19:13:21,191 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:319 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - try - end ----------
2025-03-02 19:13:21,191 - searchai.cli.interface - DEBUG - interface.py:process_search:71 - ---------- searchai/cli/interface.py - process_search() - progress.task(process results) - completed ----------
2025-03-02 19:13:21,193 - searchai.cli.interface - DEBUG - interface.py:process_search:77 - ---------- searchai/cli/interface.py - process_search() - progress.add_task(markdown generated docs) ----------
2025-03-02 19:13:21,193 - searchai.document_gen.markdown_gen - INFO - markdown_gen.py:generate_markdown:31 - Generating Markdown document
2025-03-02 19:13:21,195 - searchai.document_gen.markdown_gen - INFO - markdown_gen.py:generate_markdown:59 - Markdown document generated: /Users/namra4122/Developer/MarketAgent/searchai/generated_output/None/What_is_AI__20250302_191321.md
2025-03-02 19:13:21,195 - searchai.cli.interface - DEBUG - interface.py:process_search:80 - ---------- searchai/cli/interface.py - process_search() - progress.task(markdown generated docs) - completed ----------
2025-03-02 19:13:21,201 - searchai.cli.interface - DEBUG - interface.py:search:150 - ---------- searchai/cli/interface.py - new_event_loop() - ended ----------
2025-03-02 19:27:49,587 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:27:49,588 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:27:49,588 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:27:49,588 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:27:49,601 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:27:49,621 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:27:49,622 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:27:49,830 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:30:05,490 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:30:05,491 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:30:05,491 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:30:05,491 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:30:05,504 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:30:05,512 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:30:05,513 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:30:05,728 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:36:56,751 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:36:56,751 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:40:43,513 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:40:43,514 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:40:43,514 - searchai.cli.interface - INFO - interface.py:search:139 - Search request - Query: What is AI?, Format: markdown
2025-03-02 19:40:43,515 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:40:43,517 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:40:43,517 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:40:43,530 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:40:50,598 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select pg_catalog.version()
2025-03-02 19:40:50,600 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:40:51,007 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select current_schema()
2025-03-02 19:40:51,009 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:40:51,301 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - show standard_conforming_strings
2025-03-02 19:40:51,304 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:40:51,526 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:40:51,533 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:40:51,535 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00224s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:40:51,722 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:40:51,725 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.1917s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:40:51,790 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:40:51,792 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.259s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:40:51,876 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 19:40:51,878 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00221s] ('outputformat', 'pg_catalog')
2025-03-02 19:40:52,018 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:40:52,329 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:70 - Verifying database tables...
2025-03-02 19:40:52,329 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:40:52,330 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:40:52,332 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 19:40:52,334 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00159s] ()
2025-03-02 19:40:52,994 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:81 - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:40:52,995 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:40:53,074 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:40:53,075 - searchai.db.db_handler - INFO - db_handler.py:init_db:105 - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:40:53,075 - searchai.db.db_handler - INFO - db_handler.py:init_db:111 - Database initialized
2025-03-02 19:40:53,075 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:113 - ---------- searchai/db/db_handler.py - init_db() - end ----------
2025-03-02 19:40:53,076 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:127 - ---------- searchai/db/db_handler.py - log_user_query() - start ----------
2025-03-02 19:40:53,076 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:40:53,079 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:40:53,083 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 19:40:53,085 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00147s] ('87622c8b-467c-485a-b691-0e5059268155', 'What is AI?', 'MARKDOWN', 'pending')
2025-03-02 19:40:53,885 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:40:53,959 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:40:53,963 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 19:40:53,964 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00159s] ('87622c8b-467c-485a-b691-0e5059268155',)
2025-03-02 19:40:54,192 - searchai.db.db_handler - INFO - db_handler.py:log_user_query:146 - Logged user query: 87622c8b-467c-485a-b691-0e5059268155
2025-03-02 19:40:54,193 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:40:54,259 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:40:54,259 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:154 - ---------- searchai/db/db_handler.py - log_user_query() - end ----------
2025-03-02 19:40:54,260 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:165 - ---------- searchai/db/db_handler.py - update_query_status() - start ----------
2025-03-02 19:40:54,260 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:40:54,261 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:40:54,265 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 19:40:54,268 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00358s] ('processing', '87622c8b-467c-485a-b691-0e5059268155')
2025-03-02 19:40:54,511 - searchai.db.db_handler - INFO - db_handler.py:update_query_status:169 - Updated query 87622c8b-467c-485a-b691-0e5059268155 status to processing
2025-03-02 19:40:54,512 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:40:54,660 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:40:54,661 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:171 - ---------- searchai/db/db_handler.py - update_query_status() - end ----------
2025-03-02 19:40:54,661 - searchai.search.crew_search - INFO - crew_search.py:search:120 - Starting web search for query: What is AI?
2025-03-02 19:40:54,662 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:57 - ---------- searchai/search/crew_search.py - _run_crew() - start ----------
2025-03-02 19:40:54,662 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:60 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:40:54,664 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:71 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:40:54,664 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:75 - ---------- searchai/search/crew_search.py - search task - start----------
2025-03-02 19:40:54,665 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:93 - ---------- searchai/search/crew_search.py - search task - end ----------
2025-03-02 19:40:54,682 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:40:54,683 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mRequest to litellm:[0m
2025-03-02 19:40:54,683 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mlitellm.completion(model='gemini/gemini-1.5-pro-latest', messages=[{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], stop=['\nObservation:'], stream=False)[0m
2025-03-02 19:40:54,683 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:40:54,683 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x3106424a0>]
2025-03-02 19:40:54,683 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {}
2025-03-02 19:40:54,683 - LiteLLM - DEBUG - utils.py:print_verbose:298 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-03-02 19:40:54,692 - LiteLLM - DEBUG - transformation.py:translate_developer_role_to_system_role:115 - Translating developer role to system role for non-OpenAI providers.
2025-03-02 19:40:54,692 - LiteLLM - INFO - utils.py:_check_valid_arg:2896 - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 19:40:54,692 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2899 - 
LiteLLM: Params passed to completion() {'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'reasoning_effort': None, 'messages': [{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], 'additional_drop_params': None, 'custom_llm_provider': 'gemini', 'drop_params': None, 'model': 'gemini-1.5-pro-latest', 'n': None}
2025-03-02 19:40:54,693 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2902 - 
LiteLLM: Non-Default params passed to completion() {'stream': False, 'stop': ['\nObservation:']}
2025-03-02 19:40:54,693 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Final returned optional params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:40:54,693 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:40:54,695 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:40:54,695 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:40:54,701 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:40:54,702 - LiteLLM - DEBUG - litellm_logging.py:_print_llm_call_debugging_log:634 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU \
-H 'Content-Type: *****' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}]}, 'generationConfig': {'stop_sequences': ['\nObservation:']}}'
[0m

2025-03-02 19:40:54,702 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:40:54,702 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:40:54,708 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-03-02 19:40:55,397 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x310642b00>
2025-03-02 19:40:55,398 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x30faff8c0> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-03-02 19:40:55,541 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x310641360>
2025-03-02 19:40:55,542 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.started request=<Request [b'POST']>
2025-03-02 19:40:55,543 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.complete
2025-03-02 19:40:55,543 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.started request=<Request [b'POST']>
2025-03-02 19:40:55,543 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.complete
2025-03-02 19:40:55,544 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.started request=<Request [b'POST']>
2025-03-02 19:41:11,709 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 02 Mar 2025 14:11:11 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=15671'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-03-02 19:41:11,710 - httpx - INFO - _client.py:_send_single_request:1038 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 200 OK"
2025-03-02 19:41:11,711 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.started request=<Request [b'POST']>
2025-03-02 19:41:11,714 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.complete
2025-03-02 19:41:11,714 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.started
2025-03-02 19:41:11,715 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.complete
2025-03-02 19:41:11,715 - LiteLLM - DEBUG - utils.py:print_verbose:298 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Thought: I need to search the internet for \"What is AI?\" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {\"search_query\": \"What is AI?\"}\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "citationMetadata": {
        "citationSources": [
          {
            "startIndex": 352,
            "endIndex": 483,
            "uri": "https://online.okcu.edu/nursing/blog/the-latest-on-artificial-intelligence-in-nursing"
          },
          {
            "startIndex": 652,
            "endIndex": 801,
            "uri": "https://www.zenarate.com/blog/large-language-models-analysis/"
          },
          {
            "startIndex": 835,
            "endIndex": 991,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 1167,
            "endIndex": 1344,
            "uri": "https://www.up.ac.za/information-science/news/post_3030623-prof-marlene-holmner-presents-at-nigerian-conference"
          },
          {
            "startIndex": 1233,
            "endIndex": 1536,
            "uri": "https://articles.manupatra.com/article-details/Technology-A-Threat-to-Privacy"
          },
          {
            "startIndex": 1753,
            "endIndex": 1899,
            "uri": "https://anna.money/blog/updates/can-i-speak-to-a-human/"
          },
          {
            "startIndex": 1782,
            "endIndex": 1942,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 2159,
            "endIndex": 2310,
            "uri": "https://electroneek.com/blog/what-is-the-difference-between-conversational-and-generative-ai/"
          },
          {
            "startIndex": 2280,
            "endIndex": 2469,
            "uri": "https://www.teck.com/news/connect/issue/volume-27,-2019/table-of-contents/race21-the-path-to-value"
          },
          {
            "startIndex": 2672,
            "endIndex": 2829,
            "uri": "https://github.com/sirikumari/CodeAlpha_Integrating_Captcha"
          },
          {
            "startIndex": 2909,
            "endIndex": 3046,
            "uri": "https://beta.cragarwheel.com/filedownload?article=20672&FileName=Animal%20Machines.pdf"
          },
          {
            "startIndex": 2974,
            "endIndex": 3100,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 3128,
            "endIndex": 3284,
            "uri": "https://en.wikipedia.org/wiki/Artificial_intelligence"
          },
          {
            "startIndex": 3389,
            "endIndex": 3566,
            "uri": "https://www.up.ac.za/information-science/news/post_3030623-prof-marlene-holmner-presents-at-nigerian-conference"
          },
          {
            "startIndex": 3455,
            "endIndex": 3758,
            "uri": "https://articles.manupatra.com/article-details/Technology-A-Threat-to-Privacy"
          },
          {
            "startIndex": 3904,
            "endIndex": 4050,
            "uri": "https://anna.money/blog/updates/can-i-speak-to-a-human/"
          },
          {
            "startIndex": 3933,
            "endIndex": 4093,
            "uri": "https://www.data3.com/knowledge-centre/blog/making-computer-vision-accessible-to-everyone/"
          },
          {
            "startIndex": 4239,
            "endIndex": 4390,
            "uri": "https://electroneek.com/blog/what-is-the-difference-between-conversational-and-generative-ai/"
          },
          {
            "startIndex": 4360,
            "endIndex": 4549,
            "uri": "https://www.teck.com/news/connect/issue/volume-27,-2019/table-of-contents/race21-the-path-to-value"
          }
        ]
      },
      "avgLogprobs": -0.38807603587274964
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 435,
    "candidatesTokenCount": 46,
    "totalTokenCount": 481,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 435
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 46
      }
    ]
  },
  "modelVersion": "gemini-1.5-pro-002"
}



2025-03-02 19:41:11,717 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.started
2025-03-02 19:41:11,718 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.complete
2025-03-02 19:41:11,718 - LiteLLM - INFO - utils.py:wrapper:1084 - Wrapper: Completed Call, calling success_handler
2025-03-02 19:41:11,719 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1014 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-03-02 19:41:11,722 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:11,722 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:11,723 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:11,724 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:11,724 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:11,724 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:11,725 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:41:11,725 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:41:11,730 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:11,730 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:11,731 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1040 - Logging Details LiteLLM-Success Call streaming complete
2025-03-02 19:41:11,731 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:11,731 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:11,731 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:11,732 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.0015708
2025-03-02 19:41:11,732 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:11,732 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:14,114 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:41:14,115 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mRequest to litellm:[0m
2025-03-02 19:41:14,115 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mlitellm.completion(model='gemini/gemini-1.5-pro-latest', messages=[{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | Google Cloud\', \'link\': \'https://cloud.google.com/learn/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence is a technology that allows you to generate, classify, and perform tasks like image analysis and speech recognition.\', \'position\': 1}, {\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 2}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 3}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 4}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 5}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 6}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 7}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 8, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 9, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 10, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'What is AI in computer\'}, {\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}], stop=['\nObservation:'], stream=False)[0m
2025-03-02 19:41:14,115 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:41:14,116 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Initialized litellm callbacks, Async Success Callbacks: ['cache', <crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x3106424a0>]
2025-03-02 19:41:14,116 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {}
2025-03-02 19:41:14,116 - LiteLLM - DEBUG - utils.py:print_verbose:298 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-03-02 19:41:14,117 - LiteLLM - DEBUG - transformation.py:translate_developer_role_to_system_role:115 - Translating developer role to system role for non-OpenAI providers.
2025-03-02 19:41:14,117 - LiteLLM - INFO - utils.py:_check_valid_arg:2896 - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 19:41:14,117 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2899 - 
LiteLLM: Params passed to completion() {'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'reasoning_effort': None, 'messages': [{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | Google Cloud\', \'link\': \'https://cloud.google.com/learn/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence is a technology that allows you to generate, classify, and perform tasks like image analysis and speech recognition.\', \'position\': 1}, {\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 2}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 3}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 4}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 5}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 6}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 7}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 8, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 9, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 10, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'What is AI in computer\'}, {\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}], 'additional_drop_params': None, 'custom_llm_provider': 'gemini', 'drop_params': None, 'model': 'gemini-1.5-pro-latest', 'n': None}
2025-03-02 19:41:14,118 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2902 - 
LiteLLM: Non-Default params passed to completion() {'stream': False, 'stop': ['\nObservation:']}
2025-03-02 19:41:14,118 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Final returned optional params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:41:14,118 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:41:14,119 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:41:14,120 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:41:14,130 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:14,130 - LiteLLM - DEBUG - litellm_logging.py:_print_llm_call_debugging_log:634 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU \
-H 'Content-Type: *****' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}, {'role': 'model', 'parts': [{'text': 'Thought: I need to search the internet for "What is AI?" using the SerperDevTool.\n\nAction: Search the internet with Serper\nAction Input: {"search_query": "What is AI?"}\n\nObservation: {\'searchParameters\': {\'q\': \'What is AI?\', \'type\': \'search\', \'num\': 10, \'engine\': \'google\'}, \'organic\': [{\'title\': \'What Is Artificial Intelligence (AI)? | Google Cloud\', \'link\': \'https://cloud.google.com/learn/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence is a technology that allows you to generate, classify, and perform tasks like image analysis and speech recognition.\', \'position\': 1}, {\'title\': \'What Is Artificial Intelligence (AI)? | IBM\', \'link\': \'https://www.ibm.com/think/topics/artificial-intelligence\', \'snippet\': \'AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\', \'position\': 2}, {\'title\': \'Artificial intelligence - Wikipedia\', \'link\': \'https://en.wikipedia.org/wiki/Artificial_intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\', \'position\': 3}, {\'title\': \'What is Artificial Intelligence? - NASA\', \'link\': \'https://www.nasa.gov/what-is-artificial-intelligence/\', \'snippet\': \'Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\', \'position\': 4}, {\'title\': \'What is AI? - Artificial Intelligence Explained - AWS\', \'link\': \'https://aws.amazon.com/what-is/artificial-intelligence/\', \'snippet\': \'Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\', \'position\': 5}, {\'title\': \'What is AI? / Basic Questions - John McCarthy\', \'link\': \'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/\', \'snippet\': \'Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\', \'position\': 6}, {\'title\': \'What is (AI) Artificial Intelligence? | Online Master of Engineering\', \'link\': \'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\', \'snippet\': \'Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\', \'position\': 7}, {\'title\': \'What is AI? | College of Computing | Michigan Tech\', \'link\': \'https://www.mtu.edu/computing/ai/\', \'snippet\': \'Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\', \'position\': 8, \'sitelinks\': [{\'title\': \'Some Artificial Intelligence...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Some%20Artificial%20Intelligence%20Terms\'}, {\'title\': \'A Brief History Of Ai\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=A%20Brief%20History%20of%20AI\'}, {\'title\': \'Jobs In Artificial...\', \'link\': \'https://www.mtu.edu/computing/ai/#:~:text=Jobs%20In%20Artificial%20Intelligence\'}]}, {\'title\': \'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera\', \'link\': \'https://www.coursera.org/articles/what-is-artificial-intelligence\', \'snippet\': \'Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\', \'position\': 9, \'sitelinks\': [{\'title\': \'The History of AI: A Timeline of...\', \'link\': \'https://www.coursera.org/articles/history-of-ai\'}, {\'title\': \'Machine learning\', \'link\': \'https://www.coursera.org/articles/what-is-machine-learning\'}, {\'title\': \'What Is ChatGPT? Meaning...\', \'link\': \'https://www.coursera.org/articles/chatgpt\'}]}, {\'title\': \'What is AI (artificial intelligence)? - McKinsey & Company\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\', \'snippet\': "AI is a machine\'s ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...", \'position\': 10, \'sitelinks\': [{\'title\': \'About Quantumblack, Ai By...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=About%20QuantumBlack%2C%20AI%20by%20McKinsey,-QuantumBlack%2C%20McKinsey%27s%20AI\'}, {\'title\': \'What Is The History Of Ai?\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20history%20of%20AI%3F\'}, {\'title\': \'What Is The Ai Bill Of...\', \'link\': \'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai#:~:text=What%20is%20the%20AI%20Bill%20of%20Rights%3F\'}]}], \'peopleAlsoAsk\': [{\'question\': \'What did Elon Musk say about AI?\', \'snippet\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat to humanity.", \'title\': "Elon Musk warns of \'woke mind virus\' in AI, says it is an existential threat ...", \'link\': \'https://m.economictimes.com/tech/technology/elon-musk-warns-of-woke-mind-virus-in-ai-says-it-is-an-existential-threat-to-humanity/articleshow/118599459.cms\'}, {\'question\': \'What is an AI example?\', \'snippet\': \'So what are some examples of AI? Well, it can be almost anything. Your smartphone uses AI, as do services like digital assistants, chatbots, social media websites, and much more. Many home electronics also use AI, such as robot vacuum cleaners or security systems.\', \'title\': \'Everyday examples and applications of artificial intelligence (AI) - Tableau\', \'link\': \'https://www.tableau.com/data-insights/ai/examples\'}], \'relatedSearches\': [{\'query\': \'What is AI in computer\'}, {\'query\': \'How does ai work\'}, {\'query\': \'Chatgpt\'}, {\'query\': \'What is artificial intelligence with examples\'}, {\'query\': \'What is AI in simple words\'}, {\'query\': \'Types of ai\'}, {\'query\': \'Best definition of artificial intelligence\'}, {\'query\': \'What is AI article\'}], \'credits\': 1}'}]}], 'system_instruction': {'parts': [{'text': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}]}, 'generationConfig': {'stop_sequences': ['\nObservation:']}}'
[0m

2025-03-02 19:41:14,131 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:41:14,132 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:41:14,141 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-03-02 19:41:14,390 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16d402d70>
2025-03-02 19:41:14,391 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x30faffd40> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-03-02 19:41:14,685 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16d403130>
2025-03-02 19:41:14,686 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.started request=<Request [b'POST']>
2025-03-02 19:41:14,687 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.complete
2025-03-02 19:41:14,687 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.started request=<Request [b'POST']>
2025-03-02 19:41:14,687 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.complete
2025-03-02 19:41:14,688 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.started request=<Request [b'POST']>
2025-03-02 19:41:24,126 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 02 Mar 2025 14:11:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=8956'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-03-02 19:41:24,128 - httpx - INFO - _client.py:_send_single_request:1038 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 200 OK"
2025-03-02 19:41:24,129 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.started request=<Request [b'POST']>
2025-03-02 19:41:24,139 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.complete
2025-03-02 19:41:24,139 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.started
2025-03-02 19:41:24,139 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.complete
2025-03-02 19:41:24,140 - LiteLLM - DEBUG - utils.py:print_verbose:298 - RAW RESPONSE:
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Thought: I now have the search results. I will format them as requested.\n\nFinal Answer:\nhttps://cloud.google.com/learn/what-is-artificial-intelligence\nWhat Is Artificial Intelligence (AI)? | Google Cloud\nArtificial intelligence is a technology that allows you to generate, classify, and perform tasks like image analysis and speech recognition.\n\nhttps://www.ibm.com/think/topics/artificial-intelligence\nWhat Is Artificial Intelligence (AI)? | IBM\nAI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.\n\nhttps://en.wikipedia.org/wiki/Artificial_intelligence\nArtificial intelligence - Wikipedia\nArtificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...\n\nhttps://www.nasa.gov/what-is-artificial-intelligence/\nWhat is Artificial Intelligence? - NASA\nArtificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.\n\nhttps://aws.amazon.com/what-is/artificial-intelligence/\nWhat is AI? - Artificial Intelligence Explained - AWS\nArtificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...\n\nhttp://jmc.stanford.edu/artificial-intelligence/what-is-ai/\nWhat is AI? / Basic Questions - John McCarthy\nQ. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.\n\nhttps://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/\nWhat is (AI) Artificial Intelligence? | Online Master of Engineering\nArtificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...\n\nhttps://www.mtu.edu/computing/ai/\nWhat is AI? | College of Computing | Michigan Tech\nArtificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...\n\nhttps://www.coursera.org/articles/what-is-artificial-intelligence\nWhat Is Artificial Intelligence? Definition, Uses, and Types - Coursera\nArtificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.\n\nhttps://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai\nWhat is AI (artificial intelligence)? - McKinsey & Company\nAI is a machine's ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "citationMetadata": {
        "citationSources": [
          {
            "startIndex": 1211,
            "endIndex": 1345,
            "uri": "https://www.analyticsvidhya.com/blog/2023/07/ai-interview-questions/"
          },
          {
            "startIndex": 1481,
            "endIndex": 1626,
            "uri": "http://www.fredbf.com/disciplinas/unibratec/dsi/whatisAI.doc"
          },
          {
            "startIndex": 2344,
            "endIndex": 2466,
            "uri": "https://www.coursera.org/articles/what-is-artificial-intelligence"
          },
          {
            "startIndex": 2617,
            "endIndex": 2753,
            "uri": "https://www.jllt.com/blog/the-impact-of-ai-on-cre/"
          }
        ]
      },
      "avgLogprobs": -0.00047628481516102017
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 2073,
    "candidatesTokenCount": 596,
    "totalTokenCount": 2669,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 2073
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 596
      }
    ]
  },
  "modelVersion": "gemini-1.5-pro-002"
}



2025-03-02 19:41:24,141 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.started
2025-03-02 19:41:24,141 - httpcore.connection - DEBUG - _trace.py:trace:47 - close.complete
2025-03-02 19:41:24,141 - LiteLLM - INFO - utils.py:wrapper:1084 - Wrapper: Completed Call, calling success_handler
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1014 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:24,142 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:24,143 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.007881299999999999
2025-03-02 19:41:24,143 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:24,148 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.007881299999999999
2025-03-02 19:41:24,148 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:24,148 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:24,149 - LiteLLM - DEBUG - litellm_logging.py:success_handler:1040 - Logging Details LiteLLM-Success Call streaming complete
2025-03-02 19:41:24,149 - LiteLLM - DEBUG - cost_calculator.py:completion_cost:563 - completion_response _select_model_name_for_cost_calc: gemini/gemini-1.5-pro-latest
2025-03-02 19:41:24,149 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:24,149 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:24,149 - LiteLLM - DEBUG - litellm_logging.py:_response_cost_calculator:846 - response_cost: 0.007881299999999999
2025-03-02 19:41:24,150 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:41:24,150 - LiteLLM - DEBUG - utils.py:get_model_info:4441 - model_info: {'key': 'gemini/gemini-1.5-pro-latest', 'max_tokens': 8192, 'max_input_tokens': 1048576, 'max_output_tokens': 8192, 'input_cost_per_token': 3.5e-06, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': None, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': 7e-06, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'output_cost_per_token': 1.05e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_token_above_128k_tokens': 2.1e-05, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'litellm_provider': 'gemini', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_assistant_prefill': False, 'supports_prompt_caching': False, 'supports_audio_input': False, 'supports_audio_output': False, 'supports_pdf_input': False, 'supports_embedding_image_input': False, 'supports_native_streaming': None, 'tpm': 4000000, 'rpm': 1000}
2025-03-02 19:41:24,151 - searchai.search.crew_search - DEBUG - crew_search.py:_parse_results:158 - Raw results: https://cloud.google.com/learn/what-is-artificial-intelligence
What Is Artificial Intelligence (AI)? | Google Cloud
Artificial intelligence is a technology that allows you to generate, classify, and perform tasks like image analysis and speech recognition.

https://www.ibm.com/think/topics/artificial-intelligence
What Is Artificial Intelligence (AI)? | IBM
AI is technology that enables computers and machines to simulate human learning, comprehension, problem solving, decision making, creativity and autonomy.

https://en.wikipedia.org/wiki/Artificial_intelligence
Artificial intelligence - Wikipedia
Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, ...

https://www.nasa.gov/what-is-artificial-intelligence/
What is Artificial Intelligence? - NASA
Artificial intelligence refers to computer systems that can perform complex tasks normally done by human-reasoning, decision making, creating, etc.

https://aws.amazon.com/what-is/artificial-intelligence/
What is AI? - Artificial Intelligence Explained - AWS
Artificial Intelligence (AI) refers to the simulation of human intelligence in machines, enabling them to perform tasks that typically require human cognitive ...

http://jmc.stanford.edu/artificial-intelligence/what-is-ai/
What is AI? / Basic Questions - John McCarthy
Q. What is artificial intelligence? A. It is the science and engineering of making intelligent machines, especially intelligent computer programs.

https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/
What is (AI) Artificial Intelligence? | Online Master of Engineering
Artificial Intelligence (AI) works by simulating human intelligence through the use of algorithms, data, and computational power. The goal is to ...

https://www.mtu.edu/computing/ai/
What is AI? | College of Computing | Michigan Tech
Artificial intelligence (AI) encompasses the fields of computer and data science focused on building machines with human intelligence to perform tasks like ...

https://www.coursera.org/articles/what-is-artificial-intelligence
What Is Artificial Intelligence? Definition, Uses, and Types - Coursera
Artificial intelligence (AI) refers to computer systems capable of performing complex tasks that historically only a human could do.

https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai
What is AI (artificial intelligence)? - McKinsey & Company
AI is a machine's ability to perform the cognitive functions we associate with human minds, such as perceiving, reasoning, learning, interacting ...
2025-03-02 19:41:24,151 - searchai.search.crew_search - INFO - crew_search.py:search:140 - Search completed in 29.49 seconds. Found 10 results.
2025-03-02 19:41:24,151 - searchai.db.db_handler - DEBUG - db_handler.py:store_search_results:182 - ---------- searchai/db/db_handler.py - store_search_results() - start ----------
2025-03-02 19:41:24,151 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:41:24,152 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:41:24,153 - sqlalchemy.engine.Engine - INFO - base.py:_exec_insertmany_context:2070 - INSERT INTO search_results (id, query_id, source_url, title, snippet) VALUES ($1::VARCHAR, $2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR), ($6::VARCHAR, $7::VARCHAR, $8::VARCHAR, $9::VARCHAR, $10::VARCHAR), ($11::VARCHAR, $12::VARCHAR, $13::VARC ... 491 characters truncated ... AR, $48::VARCHAR, $49::VARCHAR, $50::VARCHAR) RETURNING search_results.created_at, search_results.id
2025-03-02 19:41:24,154 - sqlalchemy.engine.Engine - INFO - base.py:_exec_insertmany_context:2089 - [generated in 0.00019s (insertmanyvalues) 1/1 (ordered)] ('e926321e-cd1c-4539-839f-407544822b65', '87622c8b-467c-485a-b691-0e5059268155', 'https://cloud.google.com/learn/what-is-artificial-intelligence', 'What Is Artificial Intelligence (AI)? | Google Cloud', None, '07663206-ee7a-4ed8-8e6e-2ea86545a7cd', '87622c8b-467c-485a-b691-0e5059268155', 'https://www.ibm.com/think/topics/artificial-intelligence', 'What Is Artificial Intelligence (AI)? | IBM', None, '1f10fb0f-4065-4796-85ca-f796dbf43a7c', '87622c8b-467c-485a-b691-0e5059268155', 'https://en.wikipedia.org/wiki/Artificial_intelligence', 'Artificial intelligence - Wikipedia', None, '086ffd57-64d4-4c45-be40-44b7d8942c4c', '87622c8b-467c-485a-b691-0e5059268155', 'https://www.nasa.gov/what-is-artificial-intelligence/', 'What is Artificial Intelligence? - NASA', None, '6854d28e-5501-4c1f-afa2-2b232c1955a0', '87622c8b-467c-485a-b691-0e5059268155', 'https://aws.amazon.com/what-is/artificial-intelligence/', 'What is AI? - Artificial Intelligence Explained - AWS', None, 'ec89c2cd-a175-41a8-a031-f2e063cd5517', '87622c8b-467c-485a-b691-0e5059268155', 'http://jmc.stanford.edu/artificial-intelligence/what-is-ai/', 'What is AI? / Basic Questions - John McCarthy', None, '4707a380-33c9-41ae-988a-1f2b9de0cc39', '87622c8b-467c-485a-b691-0e5059268155', 'https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/', 'What is (AI) Artificial Intelligence? | Online Master of Engineering', None, '69975b78-bd88-4e6c-9bd6-db2ea3f0fc33', '87622c8b-467c-485a-b691-0e5059268155', 'https://www.mtu.edu/computing/ai/', 'What is AI? | College of Computing | Michigan Tech', None, '801aad49-e63e-49f1-a6c1-12bdc1ca2ae8', '87622c8b-467c-485a-b691-0e5059268155', 'https://www.coursera.org/articles/what-is-artificial-intelligence', 'What Is Artificial Intelligence? Definition, Uses, and Types - Coursera', None, 'c652fbd5-3bf8-4b92-b838-77437f8b62bf', '87622c8b-467c-485a-b691-0e5059268155', 'https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai', 'What is AI (artificial intelligence)? - McKinsey & Company', None)
2025-03-02 19:41:25,331 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:41:25,490 - searchai.db.db_handler - INFO - db_handler.py:store_search_results:193 - Stored 10 search results for query 87622c8b-467c-485a-b691-0e5059268155
2025-03-02 19:41:25,490 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:41:25,491 - searchai.db.db_handler - DEBUG - db_handler.py:store_search_results:195 - ---------- searchai/db/db_handler.py - store_search_results() - end ----------
2025-03-02 19:41:25,491 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:165 - ---------- searchai/db/db_handler.py - update_query_status() - start ----------
2025-03-02 19:41:25,491 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:41:25,491 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:41:25,492 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 19:41:25,492 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 31.23s ago] ('completed', '87622c8b-467c-485a-b691-0e5059268155')
2025-03-02 19:41:25,823 - searchai.db.db_handler - INFO - db_handler.py:update_query_status:169 - Updated query 87622c8b-467c-485a-b691-0e5059268155 status to completed
2025-03-02 19:41:25,824 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:41:25,883 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:41:25,884 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:171 - ---------- searchai/db/db_handler.py - update_query_status() - end ----------
2025-03-02 19:41:25,886 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:321 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - start ----------
2025-03-02 19:41:25,886 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:329 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - reasoner start ----------
2025-03-02 19:41:31,105 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:332 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - reasoner end ----------
2025-03-02 19:41:31,106 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:337 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - try - start ----------
2025-03-02 19:41:31,106 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:69 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - start ----------
2025-03-02 19:41:31,107 - searchai.reasoning.gemini_llm - INFO - gemini_llm.py:generate_content:70 - Generating content for query: What is AI?
2025-03-02 19:41:31,107 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:_create_prompt:132 - ---------- searchai/reasoning/gemini_llm.py - _create_prompt() - start ----------
2025-03-02 19:41:31,107 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:_create_prompt:161 - ---------- searchai/reasoning/gemini_llm.py - _create_prompt() - end ----------
2025-03-02 19:41:31,107 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:81 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - prompt: 
        You are an expert researcher and writer. Your task is to create a comprehensive and well-structured document
        based on the following search results. The document should address this query: "What is AI?"
        
        Here are the search results to use as your source material:
        
        Source 1:
Title: What Is Artificial Intelligence (AI)? | Google Cloud
URL: https://cloud.google.com/learn/what-is-artificial-intelligence
Summary: No description

Source 2:
Title: What Is Artificial Intelligence (AI)? | IBM
URL: https://www.ibm.com/think/topics/artificial-intelligence
Summary: No description

Source 3:
Title: Artificial intelligence - Wikipedia
URL: https://en.wikipedia.org/wiki/Artificial_intelligence
Summary: No description

Source 4:
Title: What is Artificial Intelligence? - NASA
URL: https://www.nasa.gov/what-is-artificial-intelligence/
Summary: No description

Source 5:
Title: What is AI? - Artificial Intelligence Explained - AWS
URL: https://aws.amazon.com/what-is/artificial-intelligence/
Summary: No description

Source 6:
Title: What is AI? / Basic Questions - John McCarthy
URL: http://jmc.stanford.edu/artificial-intelligence/what-is-ai/
Summary: No description

Source 7:
Title: What is (AI) Artificial Intelligence? | Online Master of Engineering
URL: https://meng.uic.edu/news-stories/ai-artificial-intelligence-what-is-the-definition-of-ai-and-how-does-ai-work/
Summary: No description

Source 8:
Title: What is AI? | College of Computing | Michigan Tech
URL: https://www.mtu.edu/computing/ai/
Summary: No description

Source 9:
Title: What Is Artificial Intelligence? Definition, Uses, and Types - Coursera
URL: https://www.coursera.org/articles/what-is-artificial-intelligence
Summary: No description

Source 10:
Title: What is AI (artificial intelligence)? - McKinsey & Company
URL: https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-ai
Summary: No description


        
        
            Format your response as a Markdown document with:
            1. A clear title (use # for the main title)
            2. Section headers (use ## for major sections and ### for subsections)
            3. Bullet points or numbered lists where appropriate
            4. Bold or italics for emphasis
            5. Code blocks if needed
            6. Citations to the source material
            
            IMPORTANT: Do NOT wrap the entire response in markdown code blocks (```).
            Write the content directly in markdown format.
            
        
        Make sure your response is informative, accurate, and directly answers the query. Use the provided search results
        as your primary source of information. If you need to make educated guesses or inferences, clearly indicate them.
        
        Write the document now.
         ----------
2025-03-02 19:41:31,108 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:85 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - _get_generation_config - start ----------
2025-03-02 19:41:31,108 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:88 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - _get_generation_config - end ----------
2025-03-02 19:41:43,434 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:generate_content:108 - ---------- searchai/reasoning/gemini_llm.py - generate_content() - end ----------
2025-03-02 19:41:43,435 - searchai.reasoning.gemini_llm - INFO - gemini_llm.py:generate_content:110 - Content generation completed in 12.33 seconds
2025-03-02 19:41:43,435 - searchai.reasoning.gemini_llm - DEBUG - gemini_llm.py:process_with_gemini:357 - ---------- searchai/reasoning/gemini_llm.py - process_with_gemini() - try - end ----------
2025-03-02 19:41:43,438 - searchai.document_gen.markdown_gen - INFO - markdown_gen.py:generate_markdown:34 - Generating Markdown document
2025-03-02 19:41:43,440 - searchai.document_gen.markdown_gen - INFO - markdown_gen.py:generate_markdown:78 - Markdown document generated: /Users/namra4122/Developer/MarketAgent/searchai/generated_output/What_is_AI__20250302_194143.md
2025-03-02 19:50:13,551 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:50:13,551 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:50:13,552 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:50:13,552 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:50:13,565 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:50:13,580 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:50:13,581 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:50:13,799 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:52:54,277 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:52:54,277 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:52:54,278 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:52:54,278 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:52:54,296 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:52:54,314 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: role "test" does not exist
2025-03-02 19:52:54,315 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: role "test" does not exist
2025-03-02 19:52:54,575 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:53:55,941 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:53:55,942 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:53:55,942 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:53:55,942 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:53:55,962 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:53:55,969 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: role "test" does not exist
2025-03-02 19:53:55,970 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: role "test" does not exist
2025-03-02 19:53:56,243 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:55:48,293 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:55:48,294 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:55:48,295 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:55:48,295 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:55:48,310 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:55:48,318 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:55:48,319 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:55:48,602 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:56:52,108 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:56:52,109 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:56:52,109 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:56:52,109 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:56:52,125 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:56:52,134 - searchai.db.db_handler - ERROR - db_handler.py:init_db:108 - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:56:52,135 - searchai.cli.interface - ERROR - interface.py:process_search:116 - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 19:56:52,391 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:57:16,588 - root - INFO - logging_config.py:setup_logging:59 - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 19:57:16,588 - searchai.cli.interface - INFO - interface.py:<module>:40 - ---------- searchai/cli/interface.py ----------
2025-03-02 19:57:16,589 - searchai.cli.interface - INFO - interface.py:search:139 - Search request - Query: What is AI?, Format: markdown
2025-03-02 19:57:16,589 - asyncio - DEBUG - selector_events.py:__init__:54 - Using selector: KqueueSelector
2025-03-02 19:57:16,590 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:89 - ---------- searchai/db/db_handler.py - init_db() - start ----------
2025-03-02 19:57:16,590 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:31 - ---------- searchai/db/db_handler.py - setup_db() - start ----------
2025-03-02 19:57:16,619 - searchai.db.db_handler - DEBUG - db_handler.py:setup_db:41 - ---------- searchai/db/db_handler.py - setup_db() - end ----------
2025-03-02 19:57:17,709 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select pg_catalog.version()
2025-03-02 19:57:17,710 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:57:17,876 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - select current_schema()
2025-03-02 19:57:17,877 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:57:18,039 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - show standard_conforming_strings
2025-03-02 19:57:18,040 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [raw sql] ()
2025-03-02 19:57:18,167 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:57:18,170 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:57:18,171 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00106s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:57:18,355 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:57:18,355 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.1852s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:57:18,396 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 19:57:18,397 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [cached since 0.2271s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 19:57:18,441 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 19:57:18,442 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00111s] ('outputformat', 'pg_catalog')
2025-03-02 19:57:18,538 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:57:18,579 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:70 - Verifying database tables...
2025-03-02 19:57:18,579 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:57:18,580 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:57:18,581 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 19:57:18,581 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00060s] ()
2025-03-02 19:57:18,723 - searchai.db.db_handler - INFO - db_handler.py:verify_tables:81 - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:57:18,724 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:57:18,765 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:57:18,765 - searchai.db.db_handler - INFO - db_handler.py:init_db:105 - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 19:57:18,765 - searchai.db.db_handler - INFO - db_handler.py:init_db:111 - Database initialized
2025-03-02 19:57:18,765 - searchai.db.db_handler - DEBUG - db_handler.py:init_db:113 - ---------- searchai/db/db_handler.py - init_db() - end ----------
2025-03-02 19:57:18,765 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:127 - ---------- searchai/db/db_handler.py - log_user_query() - start ----------
2025-03-02 19:57:18,765 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:57:18,767 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:57:18,769 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 19:57:18,770 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00073s] ('b569de8c-3ac8-400b-9d4e-528bd93a88ac', 'What is AI?', 'MARKDOWN', 'pending')
2025-03-02 19:57:19,200 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:57:19,244 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:57:19,245 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 19:57:19,246 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00055s] ('b569de8c-3ac8-400b-9d4e-528bd93a88ac',)
2025-03-02 19:57:19,372 - searchai.db.db_handler - INFO - db_handler.py:log_user_query:146 - Logged user query: b569de8c-3ac8-400b-9d4e-528bd93a88ac
2025-03-02 19:57:19,372 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:57:19,416 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:57:19,417 - searchai.db.db_handler - DEBUG - db_handler.py:log_user_query:154 - ---------- searchai/db/db_handler.py - log_user_query() - end ----------
2025-03-02 19:57:19,417 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:165 - ---------- searchai/db/db_handler.py - update_query_status() - start ----------
2025-03-02 19:57:19,417 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:50 - ---------- searchai/db/db_handler.py - get_session() - start ----------
2025-03-02 19:57:19,417 - sqlalchemy.engine.Engine - INFO - base.py:_begin_impl:1097 - BEGIN (implicit)
2025-03-02 19:57:19,419 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1896 - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 19:57:19,419 - sqlalchemy.engine.Engine - INFO - base.py:_exec_single_context:1901 - [generated in 0.00053s] ('processing', 'b569de8c-3ac8-400b-9d4e-528bd93a88ac')
2025-03-02 19:57:19,546 - searchai.db.db_handler - INFO - db_handler.py:update_query_status:169 - Updated query b569de8c-3ac8-400b-9d4e-528bd93a88ac status to processing
2025-03-02 19:57:19,546 - sqlalchemy.engine.Engine - INFO - base.py:_commit_impl:1140 - COMMIT
2025-03-02 19:57:19,589 - searchai.db.db_handler - DEBUG - db_handler.py:get_session:63 - ---------- searchai/db/db_handler.py - get_session() - end ----------
2025-03-02 19:57:19,589 - searchai.db.db_handler - DEBUG - db_handler.py:update_query_status:171 - ---------- searchai/db/db_handler.py - update_query_status() - end ----------
2025-03-02 19:57:19,590 - searchai.search.crew_search - INFO - crew_search.py:search:120 - Starting web search for query: What is AI?
2025-03-02 19:57:19,591 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:57 - ---------- searchai/search/crew_search.py - _run_crew() - start ----------
2025-03-02 19:57:19,591 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:60 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:57:19,593 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:71 - ---------- searchai/search/crew_search.py - researcher agent - start----------
2025-03-02 19:57:19,593 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:75 - ---------- searchai/search/crew_search.py - search task - start----------
2025-03-02 19:57:19,595 - searchai.search.crew_search - DEBUG - crew_search.py:_run_crew:93 - ---------- searchai/search/crew_search.py - search task - end ----------
2025-03-02 19:57:19,616 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:57:19,617 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mRequest to litellm:[0m
2025-03-02 19:57:19,617 - LiteLLM - DEBUG - utils.py:print_verbose:298 - [92mlitellm.completion(model='gemini/gemini-1.5-pro-latest', messages=[{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], stop=['\nObservation:'], stream=False)[0m
2025-03-02 19:57:19,617 - LiteLLM - DEBUG - utils.py:print_verbose:298 - 

2025-03-02 19:57:19,617 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Initialized litellm callbacks, Async Success Callbacks: [<crewai.utilities.token_counter_callback.TokenCalcHandler object at 0x1627fe6e0>]
2025-03-02 19:57:19,618 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {}
2025-03-02 19:57:19,618 - LiteLLM - DEBUG - utils.py:print_verbose:298 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-03-02 19:57:19,639 - LiteLLM - DEBUG - transformation.py:translate_developer_role_to_system_role:115 - Translating developer role to system role for non-OpenAI providers.
2025-03-02 19:57:19,639 - LiteLLM - INFO - utils.py:_check_valid_arg:2896 - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 19:57:19,639 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2899 - 
LiteLLM: Params passed to completion() {'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'stream': False, 'stream_options': None, 'stop': ['\nObservation:'], 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'reasoning_effort': None, 'messages': [{'role': 'system', 'content': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}, {'role': 'user', 'content': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}], 'additional_drop_params': None, 'custom_llm_provider': 'gemini', 'drop_params': None, 'model': 'gemini-1.5-pro-latest', 'n': None}
2025-03-02 19:57:19,640 - LiteLLM - DEBUG - utils.py:_check_valid_arg:2902 - 
LiteLLM: Non-Default params passed to completion() {'stream': False, 'stop': ['\nObservation:']}
2025-03-02 19:57:19,641 - LiteLLM - DEBUG - utils.py:print_verbose:298 - Final returned optional params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:57:19,641 - LiteLLM - DEBUG - litellm_logging.py:update_environment_variables:377 - self.optional_params: {'stop_sequences': ['\nObservation:']}
2025-03-02 19:57:19,646 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:57:19,646 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:57:19,659 - LiteLLM - DEBUG - utils.py:_get_model_info_helper:4166 - checking potential_model_names in litellm.model_cost: {'split_model': 'gemini-1.5-pro-latest', 'combined_model_name': 'gemini/gemini-1.5-pro-latest', 'stripped_model_name': 'gemini-1.5-pro-latest', 'combined_stripped_model_name': 'gemini/gemini-1.5-pro-latest', 'custom_llm_provider': 'gemini'}
2025-03-02 19:57:19,659 - LiteLLM - DEBUG - litellm_logging.py:_print_llm_call_debugging_log:634 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU \
-H 'Content-Type: *****' \
-d '{'contents': [{'role': 'user', 'parts': [{'text': '\nCurrent Task: Use the SerperDevTool to search for: What is AI?\n                \n                Instructions:\n                1. Use the search tool to find relevant results\n                2. For each result found, format it as follows:\n                   - URL on first line\n                   - Title on second line\n                   - Brief summary on following lines\n                3. Separate each result with a blank line\n                4. Return only the formatted results, no additional commentary\n\nThis is the expected criteria for your final answer: A list of search results formatted with URL, title and summary, separated by blank lines\nyou MUST return the actual complete content as the final answer, not a summary.\n\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\n\nThought:'}]}], 'system_instruction': {'parts': [{'text': 'You are Web Researcher. You are an expert web researcher specializing in finding and analyzing information from reliable sources.\nYour personal goal is: Find accurate and relevant information from credible sources\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\n\nTool Name: Search the internet with Serper\nTool Arguments: {\'search_query\': {\'description\': \'Mandatory search query you want to use to search the internet\', \'type\': \'str\'}}\nTool Description: A tool that can be used to search the internet with a search_query. Supports different search types: \'search\' (default), \'news\'\n\nIMPORTANT: Use the following format in your response:\n\n```\nThought: you should always think about what to do\nAction: the action to take, only one name of [Search the internet with Serper], just the name, exactly as it\'s written.\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using " to wrap keys and values.\nObservation: the result of the action\n```\n\nOnce all necessary information is gathered, return the following format:\n\n```\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n```'}]}, 'generationConfig': {'stop_sequences': ['\nObservation:']}}'
[0m

2025-03-02 19:57:19,661 - httpx - DEBUG - _config.py:load_ssl_context:82 - load_ssl_context verify=True cert=None trust_env=True http2=False
2025-03-02 19:57:19,661 - httpx - DEBUG - _config.py:load_ssl_context_verify:148 - load_verify_locations cafile='/Users/namra4122/Developer/MarketAgent/searchai/venv/lib/python3.10/site-packages/certifi/cacert.pem'
2025-03-02 19:57:19,666 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None
2025-03-02 19:57:19,676 - httpcore.connection - DEBUG - _trace.py:trace:47 - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15c1c89a0>
2025-03-02 19:57:19,676 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.started ssl_context=<ssl.SSLContext object at 0x162757a40> server_hostname='generativelanguage.googleapis.com' timeout=600.0
2025-03-02 19:57:19,715 - httpcore.connection - DEBUG - _trace.py:trace:47 - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x15c1c89d0>
2025-03-02 19:57:19,716 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.started request=<Request [b'POST']>
2025-03-02 19:57:19,716 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_headers.complete
2025-03-02 19:57:19,716 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.started request=<Request [b'POST']>
2025-03-02 19:57:19,716 - httpcore.http11 - DEBUG - _trace.py:trace:47 - send_request_body.complete
2025-03-02 19:57:19,716 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.started request=<Request [b'POST']>
2025-03-02 19:57:21,160 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Sun, 02 Mar 2025 14:27:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1437'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-03-02 19:57:21,160 - httpx - INFO - _client.py:_send_single_request:1038 - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 429 Too Many Requests"
2025-03-02 19:57:21,161 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.started request=<Request [b'POST']>
2025-03-02 19:57:21,162 - httpcore.http11 - DEBUG - _trace.py:trace:47 - receive_response_body.complete
2025-03-02 19:57:21,163 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.started
2025-03-02 19:57:21,163 - httpcore.http11 - DEBUG - _trace.py:trace:47 - response_closed.complete
2025-03-02 20:00:02,670 - root - INFO - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 20:00:02,670 - searchai.cli.interface - INFO - ---------- searchai/cli/interface.py ----------
2025-03-02 20:00:02,671 - searchai.cli.interface - INFO - Search request - Query: What is AI?, Format: markdown
2025-03-02 20:00:03,190 - sqlalchemy.engine.Engine - INFO - select pg_catalog.version()
2025-03-02 20:00:03,191 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:00:03,354 - sqlalchemy.engine.Engine - INFO - select current_schema()
2025-03-02 20:00:03,356 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:00:03,519 - sqlalchemy.engine.Engine - INFO - show standard_conforming_strings
2025-03-02 20:00:03,521 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:00:03,650 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:00:03,655 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:00:03,657 - sqlalchemy.engine.Engine - INFO - [generated in 0.00212s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:00:03,787 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:00:03,789 - sqlalchemy.engine.Engine - INFO - [cached since 0.134s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:00:03,833 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:00:03,835 - sqlalchemy.engine.Engine - INFO - [cached since 0.1797s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:00:03,882 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 20:00:03,883 - sqlalchemy.engine.Engine - INFO - [generated in 0.00146s] ('outputformat', 'pg_catalog')
2025-03-02 20:00:03,971 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:00:04,013 - searchai.db.db_handler - INFO - Verifying database tables...
2025-03-02 20:00:04,013 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:00:04,014 - sqlalchemy.engine.Engine - INFO - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 20:00:04,015 - sqlalchemy.engine.Engine - INFO - [generated in 0.00107s] ()
2025-03-02 20:00:04,136 - searchai.db.db_handler - INFO - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:00:04,137 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:00:04,188 - searchai.db.db_handler - INFO - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:00:04,188 - searchai.db.db_handler - INFO - Database initialized
2025-03-02 20:00:04,191 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:00:04,195 - sqlalchemy.engine.Engine - INFO - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 20:00:04,196 - sqlalchemy.engine.Engine - INFO - [generated in 0.00141s] ('25eb2a3e-d411-4a51-9192-9b4bcacba51b', 'What is AI?', 'MARKDOWN', 'pending')
2025-03-02 20:00:04,579 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:00:04,625 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:00:04,628 - sqlalchemy.engine.Engine - INFO - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 20:00:04,629 - sqlalchemy.engine.Engine - INFO - [generated in 0.00123s] ('25eb2a3e-d411-4a51-9192-9b4bcacba51b',)
2025-03-02 20:00:04,758 - searchai.db.db_handler - INFO - Logged user query: 25eb2a3e-d411-4a51-9192-9b4bcacba51b
2025-03-02 20:00:04,759 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:00:04,804 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:00:04,807 - sqlalchemy.engine.Engine - INFO - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 20:00:04,808 - sqlalchemy.engine.Engine - INFO - [generated in 0.00142s] ('processing', '25eb2a3e-d411-4a51-9192-9b4bcacba51b')
2025-03-02 20:00:04,937 - searchai.db.db_handler - INFO - Updated query 25eb2a3e-d411-4a51-9192-9b4bcacba51b status to processing
2025-03-02 20:00:04,938 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:00:04,981 - searchai.search.crew_search - INFO - Starting web search for query: What is AI?
2025-03-02 20:00:05,011 - LiteLLM - INFO - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 20:00:06,685 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 429 Too Many Requests"
2025-03-02 20:01:34,645 - root - INFO - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 20:01:34,646 - searchai.cli.interface - INFO - ---------- searchai/cli/interface.py ----------
2025-03-02 20:01:34,646 - searchai.cli.interface - INFO - Search request - Query: Latest developments in quantum computing, Format: markdown
2025-03-02 20:01:35,155 - sqlalchemy.engine.Engine - INFO - select pg_catalog.version()
2025-03-02 20:01:35,157 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:01:35,328 - sqlalchemy.engine.Engine - INFO - select current_schema()
2025-03-02 20:01:35,330 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:01:35,494 - sqlalchemy.engine.Engine - INFO - show standard_conforming_strings
2025-03-02 20:01:35,495 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:01:35,624 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:01:35,634 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:01:35,636 - sqlalchemy.engine.Engine - INFO - [generated in 0.00219s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:01:35,761 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:01:35,763 - sqlalchemy.engine.Engine - INFO - [cached since 0.1294s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:01:35,812 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:01:35,813 - sqlalchemy.engine.Engine - INFO - [cached since 0.1794s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:01:35,858 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 20:01:35,860 - sqlalchemy.engine.Engine - INFO - [generated in 0.00239s] ('outputformat', 'pg_catalog')
2025-03-02 20:01:35,946 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:01:35,991 - searchai.db.db_handler - INFO - Verifying database tables...
2025-03-02 20:01:35,993 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:01:35,994 - sqlalchemy.engine.Engine - INFO - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 20:01:35,996 - sqlalchemy.engine.Engine - INFO - [generated in 0.00173s] ()
2025-03-02 20:01:36,127 - searchai.db.db_handler - INFO - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:01:36,127 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:01:36,169 - searchai.db.db_handler - INFO - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:01:36,169 - searchai.db.db_handler - INFO - Database initialized
2025-03-02 20:01:36,171 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:01:36,174 - sqlalchemy.engine.Engine - INFO - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 20:01:36,175 - sqlalchemy.engine.Engine - INFO - [generated in 0.00125s] ('686de367-610f-475a-b58c-d73d5014aede', 'Latest developments in quantum computing', 'MARKDOWN', 'pending')
2025-03-02 20:01:36,553 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:01:36,601 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:01:36,606 - sqlalchemy.engine.Engine - INFO - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 20:01:36,608 - sqlalchemy.engine.Engine - INFO - [generated in 0.00183s] ('686de367-610f-475a-b58c-d73d5014aede',)
2025-03-02 20:01:36,741 - searchai.db.db_handler - INFO - Logged user query: 686de367-610f-475a-b58c-d73d5014aede
2025-03-02 20:01:36,742 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:01:36,786 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:01:36,790 - sqlalchemy.engine.Engine - INFO - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 20:01:36,792 - sqlalchemy.engine.Engine - INFO - [generated in 0.00192s] ('processing', '686de367-610f-475a-b58c-d73d5014aede')
2025-03-02 20:01:36,917 - searchai.db.db_handler - INFO - Updated query 686de367-610f-475a-b58c-d73d5014aede status to processing
2025-03-02 20:01:36,917 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:01:36,959 - searchai.search.crew_search - INFO - Starting web search for query: Latest developments in quantum computing
2025-03-02 20:01:36,989 - LiteLLM - INFO - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 20:01:38,502 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 429 Too Many Requests"
2025-03-02 20:05:56,379 - root - INFO - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 20:05:56,380 - searchai.cli.interface - INFO - ---------- searchai/cli/interface.py ----------
2025-03-02 20:05:56,380 - searchai.cli.interface - INFO - Search request - Query: Latest developments in quantum computing, Format: markdown
2025-03-02 20:05:56,919 - sqlalchemy.engine.Engine - INFO - select pg_catalog.version()
2025-03-02 20:05:56,921 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:05:57,083 - sqlalchemy.engine.Engine - INFO - select current_schema()
2025-03-02 20:05:57,085 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:05:57,244 - sqlalchemy.engine.Engine - INFO - show standard_conforming_strings
2025-03-02 20:05:57,246 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2025-03-02 20:05:57,369 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:05:57,378 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:05:57,380 - sqlalchemy.engine.Engine - INFO - [generated in 0.00216s] ('user_queries', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:05:57,512 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:05:57,515 - sqlalchemy.engine.Engine - INFO - [cached since 0.1366s ago] ('search_results', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:05:57,556 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_class.relname 
FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace 
WHERE pg_catalog.pg_class.relname = $1::VARCHAR AND pg_catalog.pg_class.relkind = ANY (ARRAY[$2::VARCHAR, $3::VARCHAR, $4::VARCHAR, $5::VARCHAR, $6::VARCHAR]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != $7::VARCHAR
2025-03-02 20:05:57,558 - sqlalchemy.engine.Engine - INFO - [cached since 0.1794s ago] ('generated_documents', 'r', 'p', 'f', 'v', 'm', 'pg_catalog')
2025-03-02 20:05:57,601 - sqlalchemy.engine.Engine - INFO - SELECT pg_catalog.pg_type.typname 
FROM pg_catalog.pg_type JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_type.typnamespace 
WHERE pg_catalog.pg_type.typname = $1::VARCHAR AND pg_catalog.pg_type_is_visible(pg_catalog.pg_type.oid) AND pg_catalog.pg_namespace.nspname != $2::VARCHAR
2025-03-02 20:05:57,603 - sqlalchemy.engine.Engine - INFO - [generated in 0.00218s] ('outputformat', 'pg_catalog')
2025-03-02 20:05:57,685 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:05:57,728 - searchai.db.db_handler - INFO - Verifying database tables...
2025-03-02 20:05:57,730 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:05:57,733 - sqlalchemy.engine.Engine - INFO - 
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
            
2025-03-02 20:05:57,734 - sqlalchemy.engine.Engine - INFO - [generated in 0.00197s] ()
2025-03-02 20:05:57,861 - searchai.db.db_handler - INFO - Found tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:05:57,861 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:05:57,905 - searchai.db.db_handler - INFO - Successfully verified tables: ['search_queries', 'user_queries', 'search_results', 'generated_documents']
2025-03-02 20:05:57,906 - searchai.db.db_handler - INFO - Database initialized
2025-03-02 20:05:57,910 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:05:57,914 - sqlalchemy.engine.Engine - INFO - INSERT INTO user_queries (id, query_text, output_format, status) VALUES ($1::VARCHAR, $2::VARCHAR, $3::outputformat, $4::VARCHAR) RETURNING user_queries.created_at
2025-03-02 20:05:57,915 - sqlalchemy.engine.Engine - INFO - [generated in 0.00169s] ('7b200a88-a364-4679-aad7-383fc0420f58', 'Latest developments in quantum computing', 'MARKDOWN', 'pending')
2025-03-02 20:05:58,286 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:05:58,330 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:05:58,335 - sqlalchemy.engine.Engine - INFO - SELECT user_queries.id, user_queries.query_text, user_queries.created_at, user_queries.output_format, user_queries.status 
FROM user_queries 
WHERE user_queries.id = $1::VARCHAR
2025-03-02 20:05:58,336 - sqlalchemy.engine.Engine - INFO - [generated in 0.00172s] ('7b200a88-a364-4679-aad7-383fc0420f58',)
2025-03-02 20:05:58,460 - searchai.db.db_handler - INFO - Logged user query: 7b200a88-a364-4679-aad7-383fc0420f58
2025-03-02 20:05:58,461 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:05:58,505 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2025-03-02 20:05:58,509 - sqlalchemy.engine.Engine - INFO - UPDATE user_queries SET status=$1::VARCHAR WHERE user_queries.id = $2::VARCHAR
2025-03-02 20:05:58,511 - sqlalchemy.engine.Engine - INFO - [generated in 0.00196s] ('processing', '7b200a88-a364-4679-aad7-383fc0420f58')
2025-03-02 20:05:58,632 - searchai.db.db_handler - INFO - Updated query 7b200a88-a364-4679-aad7-383fc0420f58 status to processing
2025-03-02 20:05:58,632 - sqlalchemy.engine.Engine - INFO - COMMIT
2025-03-02 20:05:58,676 - searchai.search.crew_search - INFO - Starting web search for query: Latest developments in quantum computing
2025-03-02 20:05:58,709 - LiteLLM - INFO - 
LiteLLM completion() model= gemini-1.5-pro-latest; provider = gemini
2025-03-02 20:06:00,225 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?key=AIzaSyCVNVAhh_SaSNaS5wKLu1kUcwS703rWqAU "HTTP/1.1 429 Too Many Requests"
2025-03-02 20:08:05,210 - root - INFO - Logging initialized. Log file: /Users/namra4122/Developer/MarketAgent/searchai/logs/search_20250302.log
2025-03-02 20:08:05,210 - searchai.cli.interface - INFO - ---------- searchai/cli/interface.py ----------
2025-03-02 20:08:05,233 - searchai.db.db_handler - ERROR - Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
2025-03-02 20:08:05,234 - searchai.cli.interface - ERROR - Search process failed: Database initialization failed: PostgreSQL server at "localhost:5432" rejected SSL upgrade
